{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9159a50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dillc\\Documents\\UNI\\APA\\apa_venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from search import Search\n",
    "from prompt import Prompt\n",
    "from prompt import Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93ec68d",
   "metadata": {},
   "source": [
    "## How to use the search tool\n",
    "\n",
    "This notebook demonstrates how the production (prod) search environment can be used and provides examples, it is based on the notebook found in the experimental environment, therefore, please read that one first for more accurate information.\n",
    "The notebook will mainly focus on:\n",
    "- Creating `prompt` templates\n",
    "- Creating and running `Search`\n",
    "\n",
    "### Requirements:\n",
    "For the environment to be used the following is required:\n",
    "- All libraries found in 'requirements.txt' need to be present\n",
    "- The dataset needs to have 'record_id' as the id column and 'label' (0 or 1). At least one of the following columns need to be included:\n",
    "* A column with 'openalex' in the name, which contains a link to the article on OpenAlex platform\n",
    "\n",
    "OR\n",
    "\n",
    "* 'title' and/or 'abstract' and/or 'keywords'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b58be11",
   "metadata": {},
   "source": [
    "### `prompt`\n",
    "`prompt` lets you define the template for your search prompt. Like the experimental version, it supports RAG-style prompts with 'augmentation' (context) and 'prediction' parts. In prod, you have more flexibility in prompt structure and can use a wider variety of patterns and tokens.\n",
    "\n",
    "Supported placeholders:\n",
    "- `{record_id}`: The ID of the article in the dataset\n",
    "- `{label_token}`: Custom label, using `positive_token` and `negative_token`\n",
    "- `{title}`\n",
    "- `{abstract}`\n",
    "- `{keywords}`\n",
    "\n",
    "*Note*: Use `{}` in the augmentation or prediction string to indicate where a list should appear.\n",
    "\n",
    "#### `positive_token` and `negative_token`:\n",
    "Set these for custom labeling schemes. The environment uses them to interpret LLM responses.\n",
    "\n",
    "#### `prediction_method`\n",
    "- `Methods.ID`: Model returns a list of IDs for relevant items.\n",
    "- `Methods.TOKEN`: Model returns a token (e.g., '<POSITIVE>' or '<NEGATIVE>') for each item.\n",
    "- `Methods.ID_TOKEN`: Model returns both an ID and a token for each item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99986ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: ID-based prompt for prod\n",
    "prompt = Prompt(\n",
    "    augmentation='You are given a list of items, each with an \"ID\" and a \"content\". Select the most relevant and return their IDs: {}',\n",
    "    augmentation_item_pattern='{\"ID\":\"{record_id}\", content: {title} {abstract} }',\n",
    "    prediction='{}',\n",
    "    prediction_item_pattern='{\"ID\":\"{record_id}\", content: {title} {abstract} }',\n",
    "    prediction_method=Methods.ID\n",
    ")\n",
    "\n",
    "# Example: TOKEN-based prompt for prod\n",
    "prompt_token = Prompt(\n",
    "    augmentation='given the following text: {}',\n",
    "    augmentation_item_pattern='$$$ {title} {abstract} , STATUS={label_token}  $$$',\n",
    "    prediction='Predict the STATUS, answer only with <POSITIVE> or <NEGATIVE>: {}',\n",
    "    prediction_item_pattern='$$${title} {abstract}, STATUS= ',\n",
    "    positive_token='<POSITIVE>',\n",
    "    negative_token='<NEGATIVE>',\n",
    "    prediction_method=Methods.TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a99af4c",
   "metadata": {},
   "source": [
    "### Search Object\n",
    "\n",
    "The main interface in prod is the `Search` object. Unlike the experimental version's `Experiment`, `Search` is designed for flexible querying and supports a `user_input` parameter for custom queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b644450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: create a Search object in prod\n",
    "sch = Search('example_dataset_balanced.csv',\n",
    "             columns=['title', 'abstract'],\n",
    "             user_input='Example user query or keywords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39c3bec",
   "metadata": {},
   "source": [
    "### Assign Prompt and Configure Search\n",
    "\n",
    "Assign your prompt, set batch settings, and choose a model and approach. In prod, you can use more flexible batch and prompt settings than in the experimental version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64ffeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sch.prompt = prompt\n",
    "sch.set_batch_settings(max_train_batch_size=50, max_predict_batch_size=10, batch_delay=1)\n",
    "sch.model = 'gemini-2.0-flash' \n",
    "sch.api_key='your_api_key_here'\n",
    "sch.approach = 'active'  # or 'few-shot', 'zero-shot'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc03269d",
   "metadata": {},
   "source": [
    "### Run \n",
    "\n",
    "Run the search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f78344",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = sch.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91152590",
   "metadata": {},
   "source": [
    "### Adding Positive Examples with set_initial_data\n",
    "\n",
    "You can provide additional positive examples to the Search object using `set_initial_data`. This is useful for few-shot or RAG-style prompting. The method expects a path to an augmentation dataset (CSV) and the columns to use. Only positive examples are expected in the augmentation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72315c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: add positive examples from an augmentation dataset\n",
    "sch.set_initial_data('augmentation_dataset.csv', columns=['title', 'abstract'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apa_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
